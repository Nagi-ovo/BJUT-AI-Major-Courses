{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 加载乳腺癌数据集\n",
    "cancer = load_breast_cancer()\n",
    "X_cancer = cancer.data\n",
    "y_cancer = cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "scaler = StandardScaler()\n",
    "X_cancer = scaler.fit_transform(X_cancer)\n",
    "\n",
    "# 转换为 PyTorch 张量\n",
    "X_tensor = torch.tensor(X_cancer, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y_cancer, dtype=torch.float32)\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义包含可调整k的线性模型\n",
    "class LinearModelWithTanhK(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearModelWithTanhK, self).__init__()\n",
    "        self.linear = nn.Linear(X_cancer.shape[1], 1)\n",
    "        self.k = nn.Parameter(torch.tensor([1.0]))  # 初始化k为可学习的参数\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return torch.tanh(self.k * x)\n",
    "\n",
    "# 优化函数\n",
    "def optimize_and_update_k(model, optimizer, X, y, method=\"GD\", batch_size=10, update_interval=5, increment=1.0, max_k=50.0):\n",
    "    global epoch\n",
    "    total_loss = 0.0\n",
    "\n",
    "    if method == \"SGD\":\n",
    "        indices = torch.randperm(len(X))\n",
    "        for i in range(len(X)):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(X[indices[i]:indices[i]+1]).squeeze()\n",
    "            loss = F.binary_cross_entropy_with_logits(output.unsqueeze(0), y[indices[i]:indices[i]+1])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "    elif method == \"Mini-batch SGD\":\n",
    "        indices = torch.randperm(len(X))\n",
    "        for i in range(0, len(X), batch_size):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(X[indices[i:i+batch_size]]).squeeze()\n",
    "            loss = F.binary_cross_entropy_with_logits(output, y[indices[i:i+batch_size]])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "    else:  # GD\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X).squeeze()\n",
    "        loss = F.binary_cross_entropy_with_logits(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # 更新k的值\n",
    "    if epoch % update_interval == 0 and model.k.item() < max_k:\n",
    "        with torch.no_grad():\n",
    "            model.k.add_(increment)\n",
    "\n",
    "    return total_loss / len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评估函数\n",
    "def evaluate(model, X, y):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X).squeeze()\n",
    "        predicted = torch.sigmoid(outputs) >= 0.5\n",
    "        accuracy = (predicted == y).float().mean().item()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD - Epoch: 0, Accuracy: 0.4386, k: 1.4996\n",
      "GD - Epoch: 20, Accuracy: 0.8509, k: 3.5004\n",
      "GD - Epoch: 40, Accuracy: 0.9123, k: 5.5011\n",
      "GD - Epoch: 60, Accuracy: 0.9298, k: 7.5013\n",
      "GD - Epoch: 80, Accuracy: 0.9298, k: 9.5013\n",
      "GD - Epoch: 100, Accuracy: 0.9298, k: 11.5013\n",
      "GD - Epoch: 120, Accuracy: 0.9298, k: 13.5014\n",
      "GD - Epoch: 140, Accuracy: 0.9386, k: 15.5014\n",
      "GD - Epoch: 160, Accuracy: 0.9386, k: 17.5014\n",
      "GD - Epoch: 180, Accuracy: 0.9474, k: 19.5015\n",
      "GD - Epoch: 200, Accuracy: 0.9474, k: 21.5015\n",
      "GD - Epoch: 220, Accuracy: 0.9474, k: 23.5015\n",
      "GD - Epoch: 240, Accuracy: 0.9474, k: 25.5015\n",
      "GD - Epoch: 260, Accuracy: 0.9474, k: 27.5015\n",
      "GD - Epoch: 280, Accuracy: 0.9474, k: 29.5015\n",
      "Final Epoch 299, Accuracy = 0.9474, k = 31.00152587890625\n",
      "\n",
      "SGD - Epoch: 0, Accuracy: 0.9474, k: 1.7229\n",
      "SGD - Epoch: 20, Accuracy: 0.9649, k: 4.0529\n",
      "SGD - Epoch: 40, Accuracy: 0.9561, k: 6.1160\n",
      "SGD - Epoch: 60, Accuracy: 0.9561, k: 8.1299\n",
      "SGD - Epoch: 80, Accuracy: 0.9561, k: 10.1332\n",
      "SGD - Epoch: 100, Accuracy: 0.9561, k: 12.1340\n",
      "SGD - Epoch: 120, Accuracy: 0.9561, k: 14.1342\n",
      "SGD - Epoch: 140, Accuracy: 0.9561, k: 16.1343\n",
      "SGD - Epoch: 160, Accuracy: 0.9561, k: 18.1343\n",
      "SGD - Epoch: 180, Accuracy: 0.9561, k: 20.1343\n",
      "SGD - Epoch: 200, Accuracy: 0.9561, k: 22.1343\n",
      "SGD - Epoch: 220, Accuracy: 0.9561, k: 24.1343\n",
      "SGD - Epoch: 240, Accuracy: 0.9561, k: 26.1343\n",
      "SGD - Epoch: 260, Accuracy: 0.9561, k: 28.1343\n",
      "SGD - Epoch: 280, Accuracy: 0.9561, k: 30.1343\n",
      "Final Epoch 299, Accuracy = 0.9561, k = 31.63425064086914\n",
      "\n",
      "Mini-batch SGD - Epoch: 0, Accuracy: 0.9474, k: 1.5024\n",
      "Mini-batch SGD - Epoch: 20, Accuracy: 0.9825, k: 3.6295\n",
      "Mini-batch SGD - Epoch: 40, Accuracy: 0.9825, k: 5.6412\n",
      "Mini-batch SGD - Epoch: 60, Accuracy: 0.9825, k: 7.6463\n",
      "Mini-batch SGD - Epoch: 80, Accuracy: 0.9825, k: 9.6491\n",
      "Mini-batch SGD - Epoch: 100, Accuracy: 0.9912, k: 11.6503\n",
      "Mini-batch SGD - Epoch: 120, Accuracy: 0.9825, k: 13.6517\n",
      "Mini-batch SGD - Epoch: 140, Accuracy: 0.9825, k: 15.6524\n",
      "Mini-batch SGD - Epoch: 160, Accuracy: 0.9825, k: 17.6528\n",
      "Mini-batch SGD - Epoch: 180, Accuracy: 0.9825, k: 19.6529\n",
      "Mini-batch SGD - Epoch: 200, Accuracy: 0.9825, k: 21.6529\n",
      "Mini-batch SGD - Epoch: 220, Accuracy: 0.9825, k: 23.6529\n",
      "Mini-batch SGD - Epoch: 240, Accuracy: 0.9825, k: 25.6529\n",
      "Mini-batch SGD - Epoch: 260, Accuracy: 0.9825, k: 27.6529\n",
      "Mini-batch SGD - Epoch: 280, Accuracy: 0.9825, k: 29.6529\n",
      "Final Epoch 299, Accuracy = 0.9825,  k = 31.152942657470703\n"
     ]
    }
   ],
   "source": [
    "# 初始化模型和优化器\n",
    "lr = 0.01\n",
    "num_epochs = 300\n",
    "increment = 0.5\n",
    "\n",
    "\n",
    "# 梯度下降（GD）\n",
    "model_gd = LinearModelWithTanhK()\n",
    "optimizer_gd = torch.optim.SGD(model_gd.parameters(), lr=lr)\n",
    "for epoch in range(num_epochs):\n",
    "    optimize_and_update_k(model_gd, optimizer_gd, X_train, y_train, method=\"GD\", update_interval=5, increment=increment)\n",
    "    if epoch % 20 == 0:\n",
    "        acc_gd = evaluate(model_gd, X_test, y_test)\n",
    "        print(f\"GD - Epoch: {epoch}, Accuracy: {acc_gd:.4f}, k: {model_gd.k.item():.4f}\")\n",
    "print(f\"Final Epoch {epoch}, Accuracy = {acc_gd:.4f}, k = {model_gd.k.item()}\\n\")\n",
    "\n",
    "# 随机梯度下降（SGD）\n",
    "model_sgd = LinearModelWithTanhK()\n",
    "optimizer_sgd = torch.optim.SGD(model_sgd.parameters(), lr=lr)\n",
    "for epoch in range(num_epochs):\n",
    "    optimize_and_update_k(model_sgd, optimizer_sgd, X_train, y_train, method=\"SGD\", update_interval=5, increment=increment)\n",
    "    if epoch % 20== 0:\n",
    "        acc_sgd = evaluate(model_sgd, X_test, y_test)\n",
    "        print(f\"SGD - Epoch: {epoch}, Accuracy: {acc_sgd:.4f}, k: {model_sgd.k.item():.4f}\")\n",
    "print(f\"Final Epoch {epoch}, Accuracy = {acc_sgd:.4f}, k = {model_sgd.k.item()}\\n\")\n",
    "\n",
    "# 小批量梯度下降（Mini-batch SGD）\n",
    "model_mini_batch_sgd = LinearModelWithTanhK()\n",
    "optimizer_mini_batch_sgd = torch.optim.SGD(model_mini_batch_sgd.parameters(), lr=lr)\n",
    "for epoch in range(num_epochs):\n",
    "    optimize_and_update_k(model_mini_batch_sgd, optimizer_mini_batch_sgd, X_train, y_train, method=\"Mini-batch SGD\", update_interval=5, increment=increment)\n",
    "    if epoch % 20 == 0:\n",
    "        acc_mini_batch_sgd = evaluate(model_mini_batch_sgd, X_test, y_test)\n",
    "        print(f\"Mini-batch SGD - Epoch: {epoch}, Accuracy: {acc_mini_batch_sgd:.4f}, k: {model_mini_batch_sgd.k.item():.4f}\")\n",
    "print(f\"Final Epoch {epoch}, Accuracy = {acc_mini_batch_sgd:.4f},  k = {model_mini_batch_sgd.k.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Accuracy: 0.5614\n",
      "Epoch: 20, Accuracy: 0.5789\n",
      "Epoch: 40, Accuracy: 0.5614\n",
      "Epoch: 60, Accuracy: 0.5351\n",
      "Epoch: 80, Accuracy: 0.5789\n",
      "Epoch: 100, Accuracy: 0.5789\n",
      "Epoch: 120, Accuracy: 0.5702\n",
      "Epoch: 140, Accuracy: 0.5702\n",
      "Epoch: 160, Accuracy: 0.5175\n",
      "Epoch: 180, Accuracy: 0.5702\n",
      "Epoch: 200, Accuracy: 0.5702\n",
      "Epoch: 220, Accuracy: 0.5702\n",
      "Epoch: 240, Accuracy: 0.5702\n",
      "Epoch: 260, Accuracy: 0.5702\n",
      "Epoch: 280, Accuracy: 0.5702\n"
     ]
    }
   ],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, num_features):\n",
    "        self.weights = torch.zeros(num_features, dtype=torch.float32)\n",
    "        self.bias = torch.tensor([0.0], dtype=torch.float32)\n",
    "\n",
    "    def forward(self, x):\n",
    "        linear_output = torch.dot(x, self.weights) + self.bias\n",
    "        return torch.sign(linear_output)\n",
    "\n",
    "    def update_weights(self, x, y, lr=0.01):\n",
    "        prediction = self.forward(x)\n",
    "        self.weights += lr * (y - prediction) * x\n",
    "        self.bias += lr * (y - prediction)\n",
    "\n",
    "# 评估函数\n",
    "def evaluate(model, X, y):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y_true in zip(X, y):\n",
    "            prediction = model.forward(x)\n",
    "            if prediction == y_true:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "    return correct / total\n",
    "\n",
    "perceptron = Perceptron(num_features=X_train.shape[1])\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for x, y in zip(X_train, y_train):\n",
    "        perceptron.update_weights(x, y, lr=0.01)\n",
    "\n",
    "    if epoch % 20 == 0:\n",
    "        accuracy = evaluate(perceptron, X_test, y_test)\n",
    "        print(f'Epoch: {epoch}, Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 299, Accuracy: 0.9298\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 创建感知机模型\n",
    "clf = Perceptron()\n",
    "\n",
    "# 训练模型\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Epoch: {epoch}, Accuracy: {accuracy:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
