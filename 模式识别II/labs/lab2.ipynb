{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1．实现公开的MNIST手写数字数据集的分类或自选数据的分类；包括数据获取、训练集和测试集创建、工作空间创建、训练数据导入； \n",
    "\n",
    "2．调用scikit-learn的基本库，自己实现利用Parzen窗、Gaussian 分布和KNN实现MINIST的概率密度估计并进行分类,及基于训练好模型的测试、实验报告撰写。\n",
    "\n",
    "3．利用第三方优化工具包实现参数的优化，并与scikit-learn中标准算法进行自己实现算法的时间复杂度的对比。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/datasci/lib/python3.9/site-packages/sklearn/datasets/_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn import manifold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 获取数据\n",
    "data = datasets.fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "pixel_values, targets = data\n",
    "targets = targets.astype(int)\n",
    "pixel_array = pixel_values.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 t-SNE 进行降维\n",
    "tsne = manifold.TSNE(n_components=2, random_state=42, perplexity=25)\n",
    "transformed_data = tsne.fit_transform(pixel_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 DataFrame\n",
    "tsne_df = pd.DataFrame(np.column_stack((transformed_data, targets)),\n",
    "                       columns=[\"x\", \"y\", \"targets\"])\n",
    "tsne_df.loc[:, \"targets\"] = tsne_df.targets.astype(int)\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train = transformed_data[:60000]\n",
    "y_train = targets[:60000]\n",
    "X_test = transformed_data[60000:]\n",
    "y_test = targets[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# 执行 Parzen 窗口密度估计的函数\n",
    "\n",
    "def parzen_window_estimation_optimized(X_train, X_test, h):\n",
    "    # 计算所有测试样本和所有训练样本之间的距离\n",
    "    distances = cdist(X_test, X_train, 'euclidean')\n",
    "    # 计算 Parzen 窗口\n",
    "    kernel_values = np.exp(-0.5 * (distances / h) ** 2) / (np.sqrt(2 * np.pi) * h)\n",
    "    # 求每个测试样本的平均密度\n",
    "    return kernel_values.mean(axis=1)\n",
    "\n",
    "# 根据 Parzen 窗口估计进行分类的函数\n",
    "def classify_parzen_window(X_train, y_train, X_test, h):\n",
    "    unique_classes = np.unique(y_train)\n",
    "    predictions = np.zeros(X_test.shape[0])\n",
    "    for class_val in unique_classes:\n",
    "        # 对每个类应用 Parzen 窗口估计\n",
    "        class_mask = y_train == class_val\n",
    "        pdf_estimates = parzen_window_estimation_optimized(X_train[class_mask], X_test, h)\n",
    "        # 假设类别概率相等，取似然度最大值\n",
    "        if class_val == 0 or pdf_estimates > predictions:\n",
    "            predictions = pdf_estimates\n",
    "            predicted_class = class_val\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "# 为 Parzen 窗口设置带宽参数\n",
    "h = 0.42813323987193935 # 这是在一次失败的实验中得到的最佳参数，其实0.5左右的参数效果差不多。 \n",
    "\n",
    "predictions = []\n",
    "n_test_samples = len(X_test)\n",
    "print_interval = 1000  # 每处理1000张图片打印一次进度\n",
    "print(n_test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已处理 1000 / 10000 张图片\n",
      "已处理 2000 / 10000 张图片\n",
      "已处理 3000 / 10000 张图片\n",
      "已处理 4000 / 10000 张图片\n",
      "已处理 5000 / 10000 张图片\n",
      "已处理 6000 / 10000 张图片\n",
      "已处理 7000 / 10000 张图片\n",
      "已处理 8000 / 10000 张图片\n",
      "已处理 9000 / 10000 张图片\n",
      "已处理 10000 / 10000 张图片\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_test_samples):\n",
    "    prediction = classify_parzen_window(X_train, y_train, X_test[i].reshape(1, -1), h)\n",
    "    predictions.append(prediction)\n",
    "\n",
    "    # 每处理1000张图片时打印进度\n",
    "    if (i + 1) % print_interval == 0 or i == n_test_samples - 1:\n",
    "        print(f\"已处理 {i + 1} / {n_test_samples} 张图片\")\n",
    "\n",
    "predictions = np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率: 0.9731\n"
     ]
    }
   ],
   "source": [
    "# 计算准确率\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'准确率: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率: 0.97260\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 创建 k-NN 分类器实例\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# 训练分类器\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# 进行预测\n",
    "predictions = knn.predict(X_test)\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'准确率: {accuracy:.5f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
