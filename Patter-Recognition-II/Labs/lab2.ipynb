{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1．实现公开的MNIST手写数字数据集的分类或自选数据的分类；包括数据获取、训练集和测试集创建、工作空间创建、训练数据导入； \n",
    "\n",
    "2．调用scikit-learn的基本库，自己实现利用Parzen窗、Gaussian 分布和KNN实现MINIST的概率密度估计并进行分类,及基于训练好模型的测试、实验报告撰写。\n",
    "\n",
    "3．利用第三方优化工具包实现参数的优化，并与scikit-learn中标准算法进行自己实现算法的时间复杂度的对比。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/datasci/lib/python3.9/site-packages/sklearn/datasets/_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.neighbors import KernelDensity, KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "data = datasets.fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "pixel_values, targets = data\n",
    "targets = targets.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集和测试集\n",
    "X_train = pixel_values.to_numpy()[:60000, :]\n",
    "y_train = targets[:60000]\n",
    "X_test = pixel_values.to_numpy()[60000:, :]\n",
    "y_test = targets[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parzen窗估计 \n",
    "kde = KernelDensity(kernel='gaussian', bandwidth=3.0).fit(X_train)\n",
    "log_densities = kde.score_samples(X_train[:10, :])  # 这里只是计算训练数据前10个样本的log密度，仅为示例\n",
    "print(\"Log densities of first 10 training samples:\", log_densities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN分类\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test[:10000, :]) \n",
    "accuracy = accuracy_score(y_test[:10000], y_pred)\n",
    "print(f\"KNN Accuracy : {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
